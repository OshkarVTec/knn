{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de K-nearest-neighbors\n",
    "\n",
    "* Oskar Adolfo Villa\n",
    "* Cruz Daniel Pérez\n",
    "* Rogelio Hernández"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente clase contiene todo el código necesario para ejecutar un algoritmo de KNN con distancia euclidiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.data = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.data = [(x, label) for x, label in zip(X, y)]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        results = []\n",
    "\n",
    "        for idx, x in enumerate(X_test):\n",
    "            neighbors = self._get_neighbors(x)\n",
    "            # assigned_class = self._vote(neighbors)\n",
    "            assigned_class = self._vote_manual(neighbors)\n",
    "            class_count = self._count_neighbors(neighbors)\n",
    "\n",
    "            results.append({\n",
    "                \"Instance\": idx + 1,\n",
    "                \"tested_negative\": class_count.get(\"tested_negative\", 0),\n",
    "                \"tested_positive\": class_count.get(\"tested_positive\", 0),\n",
    "                \"Assigned class\": assigned_class\n",
    "            })\n",
    "\n",
    "            predictions.append(assigned_class)\n",
    "\n",
    "        return predictions, results\n",
    "\n",
    "    def _get_neighbors(self, x):\n",
    "        distances = []\n",
    "        for point, label in self.data:\n",
    "            dist = self._euclidean_distance(x, point)\n",
    "            distances.append((dist, label))\n",
    "        distances.sort(key=lambda d: d[0])\n",
    "        return distances[:self.k]\n",
    "    \n",
    "    # def _vote(self, neighbors):\n",
    "    #     votes = {}\n",
    "    #     for _, label in neighbors:\n",
    "    #         votes[label] = votes.get(label, 0) + 1\n",
    "    #     return max(votes, key=votes.get)\n",
    "\n",
    "    @staticmethod\n",
    "    def _euclidean_distance(x1, x2):\n",
    "        return math.sqrt(sum((a - b) ** 2 for a, b in zip(x1, x2)))\n",
    "\n",
    "    def _count_neighbors(self, neighbors):\n",
    "        count = {}\n",
    "        for _, label in neighbors:\n",
    "            if label in count:\n",
    "                count[label] += 1\n",
    "            else:\n",
    "                count[label] = 1\n",
    "        return count\n",
    "\n",
    "    def _vote_manual(self, neighbors):\n",
    "        count = self._count_neighbors(neighbors)\n",
    "        assigned = None\n",
    "        max_votes = -1\n",
    "        for label, num in count.items():\n",
    "            if num > max_votes:\n",
    "                max_votes = num\n",
    "                assigned = label\n",
    "        return assigned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(k=3, normalize=False):\n",
    "    train = pd.read_csv(\"Diabetes-Entrenamiento.csv\")\n",
    "    test = pd.read_csv(\"Diabetes-Clasificacion.csv\")\n",
    "\n",
    "    X_train = train.drop(columns=[\"class\"]).values\n",
    "    y_train = train[\"class\"].values\n",
    "    X_test = test.drop(columns=[\"class\"]).values\n",
    "    y_test = test[\"class\"].values\n",
    "\n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    knn = KNearestNeighbors(k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions, results = knn.predict(X_test)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df[\"True class\"] = y_test\n",
    "    results_df[\"Correct\"] = results_df[\"Assigned class\"] == results_df[\"True class\"]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy with k = {k}, normalized = {normalize}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución con distintos valores de k y normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k = 1, normalized = False: 67.00%\n",
      "Accuracy with k = 3, normalized = False: 70.00%\n",
      "Accuracy with k = 7, normalized = False: 74.00%\n",
      "Accuracy with k = 1, normalized = True: 72.00%\n",
      "Accuracy with k = 3, normalized = True: 83.00%\n",
      "Accuracy with k = 7, normalized = True: 77.00%\n"
     ]
    }
   ],
   "source": [
    "res1 = run_knn(k=1, normalize=False)\n",
    "res2 = run_knn(k=3, normalize=False)\n",
    "res3 = run_knn(k=7, normalize=False)\n",
    "\n",
    "res4 = run_knn(k=1, normalize=True)\n",
    "res5 = run_knn(k=3, normalize=True)\n",
    "res6 = run_knn(k=7, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **¿Cómo varía el resultado con diferentes valores de k?**  \n",
    "    Se observó que, sin normalización, la precisión del algoritmo KNN fue aumentando ligeramente al incrementar el valor de k: con k=1 se obtuvo un 67.00%, con k=3 un 70.00%, y con k=7 un 74.00%. Esto indica que al considerar más vecinos, el modelo logra tomar decisiones más estables, lo que mejora la precisión. Sin embargo, en el caso con datos normalizados, el mejor resultado se obtuvo con k=3 (83.00%), mientras que k=1 y k=7 dieron precisiones menores (72.00% y 77.00%, respectivamente), lo que sugiere que hay un punto óptimo para k y no siempre un valor mayor es mejor.\n",
    "2. **¿Tiene inferencia en el resultado el que los datos estén normalizados?**  \n",
    "    Sí, la normalización tuvo un impacto significativo en los resultados. Comparando cada valor de k, se obtuvo una mayor precisión cuando los datos estaban normalizados. Por ejemplo, con k=3, la precisión pasó de 70.00% sin normalizar a 83.00% con normalización. Esto confirma que al usar distancia euclidiana, la normalización es esencial para evitar que atributos con valores grandes dominen el cálculo de la distancia.\n",
    "\n",
    "3. **¿Cuáles fueron los resultados mínimos y máximos obtenidos en los experimentos?**  \n",
    "    El resultado mínimo fue de 67.00% (k=1 sin normalización), y el máximo fue de 83.00% (k=3 con normalización). Esto representa una mejora del 16% entre el peor y el mejor escenario, lo cual demuestra la importancia tanto del valor de k como de la normalización en el rendimiento del algoritmo KNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar resultados en archivo CSV y mostrar precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como resultados_k3.csv\n",
      "Precisión: 70.00% (70/100)\n",
      "Archivo guardado como resultados_k3_normalizado.csv\n",
      "Precisión: 83.00% (83/100)\n"
     ]
    }
   ],
   "source": [
    "def save_and_display(results_df, file_name):\n",
    "    results_df[[\"Instance\", \"tested_negative\", \"tested_positive\", \"Assigned class\"]].to_csv(file_name, index=False)\n",
    "    correct = results_df[\"Correct\"].sum()\n",
    "    total = len(results_df)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Archivo guardado como {file_name}\")\n",
    "    print(f\"Precisión: {accuracy:.2f}% ({correct}/{total})\")\n",
    "\n",
    "save_and_display(res2, \"resultados_k3.csv\")\n",
    "save_and_display(res5, \"resultados_k3_normalizado.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
